{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2531,"status":"ok","timestamp":1660464555262,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"},"user_tz":-540},"id":"1Akhgz4Xei5E","outputId":"3ca6b274-0863-4ad4-823f-b38a1cbc7cc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INF3UHk4eple","outputId":"cbca0585-7acc-4ae6-b2fc-3057a95cd874","executionInfo":{"status":"ok","timestamp":1660464045033,"user_tz":-540,"elapsed":1760007,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","Collecting torch-scatter\n","  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n","Building wheels for collected packages: torch-scatter\n","  Building wheel for torch-scatter (setup.py): started\n","  Building wheel for torch-scatter (setup.py): finished with status 'done'\n","  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=3567066 sha256=d81e8e57d16f5222578f22a4707a166e6cd78e9761b47d06d44136ac3a37f91f\n","  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n","Successfully built torch-scatter\n","Installing collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","Collecting torch-sparse\n","  Downloading torch_sparse-0.6.14.tar.gz (51 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n","Building wheels for collected packages: torch-sparse\n","  Building wheel for torch-sparse (setup.py): started\n","  Building wheel for torch-sparse (setup.py): finished with status 'done'\n","  Created wheel for torch-sparse: filename=torch_sparse-0.6.14-cp37-cp37m-linux_x86_64.whl size=1703238 sha256=0a6ff585b641695b76abb41c955feaabeca0b356d16ef58a9c20a22f28fd364b\n","  Stored in directory: /root/.cache/pip/wheels/3c/aa/62/db0259eae2abce84f1ee2cf1c531bba683aab4bf79054172f8\n","Successfully built torch-sparse\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.14\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","Collecting torch-cluster\n","  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n","Building wheels for collected packages: torch-cluster\n","  Building wheel for torch-cluster (setup.py): started\n","  Building wheel for torch-cluster (setup.py): finished with status 'done'\n","  Created wheel for torch-cluster: filename=torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl size=940990 sha256=950f7c883950b1aa15166bf2cc4e44abec29ce43721f75c253fb56158c64dc97\n","  Stored in directory: /root/.cache/pip/wheels/bc/c7/3e/258dd72b35d7a459264143ad5bfe97b9dc5eef90069ca2f13f\n","Successfully built torch-cluster\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","Collecting torch-spline-conv\n","  Downloading torch_spline_conv-1.2.1.tar.gz (13 kB)\n","Building wheels for collected packages: torch-spline-conv\n","  Building wheel for torch-spline-conv (setup.py): started\n","  Building wheel for torch-spline-conv (setup.py): finished with status 'done'\n","  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl size=359962 sha256=14a17b6bbce84b6efac7b6e052f7cbdf098eae014177005e6f478f243170bac4\n","  Stored in directory: /root/.cache/pip/wheels/9c/33/73/780370b7c7bdf2340c0a7b971e915643f14795b4caa7a9a31f\n","Successfully built torch-spline-conv\n","Installing collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n"]}],"source":["%%bash\n","pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n","pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOkJvS1Meun8","outputId":"7aac7b59-1069-486c-b02e-9244ad14f795","executionInfo":{"status":"ok","timestamp":1660464050082,"user_tz":-540,"elapsed":5050,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n","\u001b[K     |████████████████████████████████| 407 kB 35.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=367b9e9b887ea19ed0c9c00b84eee3f628014c3d876574cd93d6d824bc14ed3b\n","  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.0.4\n"]}],"source":["pip install torch-geometric"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPiFwbVrewkT","outputId":"44e0d18a-4495-4ca8-c97a-1764f27ed78a","executionInfo":{"status":"ok","timestamp":1660464053558,"user_tz":-540,"elapsed":3476,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n","\u001b[K     |████████████████████████████████| 509 kB 29.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n","Installing collected packages: timm\n","Successfully installed timm-0.6.7\n"]}],"source":["pip install timm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"z61UhHu0exH_","executionInfo":{"status":"ok","timestamp":1660464560916,"user_tz":-540,"elapsed":2792,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","cudnn.benchmark = True\n","plt.ion()   # 대화형 모드"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"L9_k96VjeypY","executionInfo":{"status":"ok","timestamp":1660464568075,"user_tz":-540,"elapsed":4459,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["# pretrained model 불러오기\n","path = '/content/drive/MyDrive/pretrained/pvig_b.pth.tar'\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model_state_dict = torch.load(path, map_location=device)\n","# print(model_state_dict)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gG3rus_0e0-5","executionInfo":{"status":"ok","timestamp":1660464570417,"user_tz":-540,"elapsed":293,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["# 2022.06.17-Changed for building ViG model\n","#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n","# modified from https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py\n","# Copyright (c) Meta Platforms, Inc. and affiliates.\n","# All rights reserved.\n","\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","# --------------------------------------------------------\n","# Position embedding utils\n","# --------------------------------------------------------\n","\n","import numpy as np\n","\n","import torch\n","\n","# --------------------------------------------------------\n","# relative position embedding\n","# References: https://arxiv.org/abs/2009.13658\n","# --------------------------------------------------------\n","def get_2d_relative_pos_embed(embed_dim, grid_size):\n","    \"\"\"\n","    grid_size: int of the grid height and width\n","    return:\n","    pos_embed: [grid_size*grid_size, grid_size*grid_size]\n","    \"\"\"\n","    pos_embed = get_2d_sincos_pos_embed(embed_dim, grid_size)\n","    relative_pos = 2 * np.matmul(pos_embed, pos_embed.transpose()) / pos_embed.shape[1]\n","    return relative_pos\n","\n","\n","# --------------------------------------------------------\n","# 2D sine-cosine position embedding\n","# References:\n","# Transformer: https://github.com/tensorflow/models/blob/master/official/nlp/transformer/model_utils.py\n","# MoCo v3: https://github.com/facebookresearch/moco-v3\n","# --------------------------------------------------------\n","def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n","    \"\"\"\n","    grid_size: int of the grid height and width\n","    return:\n","    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n","    \"\"\"\n","    grid_h = np.arange(grid_size, dtype=np.float32)\n","    grid_w = np.arange(grid_size, dtype=np.float32)\n","    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n","    grid = np.stack(grid, axis=0)\n","\n","    grid = grid.reshape([2, 1, grid_size, grid_size])\n","    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n","    if cls_token:\n","        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n","    return pos_embed\n","\n","\n","def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n","    assert embed_dim % 2 == 0\n","\n","    # use half of dimensions to encode grid_h\n","    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n","    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n","\n","    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n","    return emb\n","\n","\n","def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n","    \"\"\"\n","    embed_dim: output dimension for each position\n","    pos: a list of positions to be encoded: size (M,)\n","    out: (M, D)\n","    \"\"\"\n","    assert embed_dim % 2 == 0\n","    omega = np.arange(embed_dim // 2, dtype=np.float)\n","    omega /= embed_dim / 2.\n","    omega = 1. / 10000**omega  # (D/2,)\n","\n","    pos = pos.reshape(-1)  # (M,)\n","    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n","\n","    emb_sin = np.sin(out) # (M, D/2)\n","    emb_cos = np.cos(out) # (M, D/2)\n","\n","    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n","    return emb"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LXxewF0je2XG","executionInfo":{"status":"ok","timestamp":1660464572098,"user_tz":-540,"elapsed":461,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["# 2022.06.17-Changed for building ViG model\n","#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n","import math\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","\n","def pairwise_distance(x):\n","    \"\"\"\n","    Compute pairwise distance of a point cloud.\n","    Args:\n","        x: tensor (batch_size, num_points, num_dims)\n","    Returns:\n","        pairwise distance: (batch_size, num_points, num_points)\n","    \"\"\"\n","    with torch.no_grad():\n","        x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n","        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n","        return x_square + x_inner + x_square.transpose(2, 1)\n","\n","\n","def part_pairwise_distance(x, start_idx=0, end_idx=1):\n","    \"\"\"\n","    Compute pairwise distance of a point cloud.\n","    Args:\n","        x: tensor (batch_size, num_points, num_dims)\n","    Returns:\n","        pairwise distance: (batch_size, num_points, num_points)\n","    \"\"\"\n","    with torch.no_grad():\n","        x_part = x[:, start_idx:end_idx]\n","        x_square_part = torch.sum(torch.mul(x_part, x_part), dim=-1, keepdim=True)\n","        x_inner = -2*torch.matmul(x_part, x.transpose(2, 1))\n","        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n","        return x_square_part + x_inner + x_square.transpose(2, 1)\n","\n","\n","def xy_pairwise_distance(x, y):\n","    \"\"\"\n","    Compute pairwise distance of a point cloud.\n","    Args:\n","        x: tensor (batch_size, num_points, num_dims)\n","    Returns:\n","        pairwise distance: (batch_size, num_points, num_points)\n","    \"\"\"\n","    with torch.no_grad():\n","        xy_inner = -2*torch.matmul(x, y.transpose(2, 1))\n","        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n","        y_square = torch.sum(torch.mul(y, y), dim=-1, keepdim=True)\n","        return x_square + xy_inner + y_square.transpose(2, 1)\n","\n","\n","def dense_knn_matrix(x, k=16, relative_pos=None):\n","    \"\"\"Get KNN based on the pairwise distance.\n","    Args:\n","        x: (batch_size, num_dims, num_points, 1)\n","        k: int\n","    Returns:\n","        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n","    \"\"\"\n","    with torch.no_grad():\n","        x = x.transpose(2, 1).squeeze(-1)\n","        batch_size, n_points, n_dims = x.shape\n","        ### memory efficient implementation ###\n","        n_part = 10000\n","        if n_points > n_part:\n","            nn_idx_list = []\n","            groups = math.ceil(n_points / n_part)\n","            for i in range(groups):\n","                start_idx = n_part * i\n","                end_idx = min(n_points, n_part * (i + 1))\n","                dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n","                if relative_pos is not None:\n","                    dist += relative_pos[:, start_idx:end_idx]\n","                _, nn_idx_part = torch.topk(-dist, k=k)\n","                nn_idx_list += [nn_idx_part]\n","            nn_idx = torch.cat(nn_idx_list, dim=1)\n","        else:\n","            dist = pairwise_distance(x.detach())\n","            if relative_pos is not None:\n","                dist += relative_pos\n","            _, nn_idx = torch.topk(-dist, k=k) # b, n, k\n","        ######\n","        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n","    return torch.stack((nn_idx, center_idx), dim=0)\n","\n","\n","def xy_dense_knn_matrix(x, y, k=16, relative_pos=None):\n","    \"\"\"Get KNN based on the pairwise distance.\n","    Args:\n","        x: (batch_size, num_dims, num_points, 1)\n","        k: int\n","    Returns:\n","        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n","    \"\"\"\n","    with torch.no_grad():\n","        x = x.transpose(2, 1).squeeze(-1)\n","        y = y.transpose(2, 1).squeeze(-1)\n","        batch_size, n_points, n_dims = x.shape\n","        dist = xy_pairwise_distance(x.detach(), y.detach())\n","        if relative_pos is not None:\n","            dist += relative_pos\n","        _, nn_idx = torch.topk(-dist, k=k)\n","        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n","    return torch.stack((nn_idx, center_idx), dim=0)\n","\n","\n","class DenseDilated(nn.Module):\n","    \"\"\"\n","    Find dilated neighbor from neighbor list\n","\n","    edge_index: (2, batch_size, num_points, k)\n","    \"\"\"\n","    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n","        super(DenseDilated, self).__init__()\n","        self.dilation = dilation\n","        self.stochastic = stochastic\n","        self.epsilon = epsilon\n","        self.k = k\n","\n","    def forward(self, edge_index):\n","        if self.stochastic:\n","            if torch.rand(1) < self.epsilon and self.training:\n","                num = self.k * self.dilation\n","                randnum = torch.randperm(num)[:self.k]\n","                edge_index = edge_index[:, :, :, randnum]\n","            else:\n","                edge_index = edge_index[:, :, :, ::self.dilation]\n","        else:\n","            edge_index = edge_index[:, :, :, ::self.dilation]\n","        return edge_index\n","\n","\n","class DenseDilatedKnnGraph(nn.Module):\n","    \"\"\"\n","    Find the neighbors' indices based on dilated knn\n","    \"\"\"\n","    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n","        super(DenseDilatedKnnGraph, self).__init__()\n","        self.dilation = dilation\n","        self.stochastic = stochastic\n","        self.epsilon = epsilon\n","        self.k = k\n","        self._dilated = DenseDilated(k, dilation, stochastic, epsilon)\n","\n","    def forward(self, x, y=None, relative_pos=None):\n","        if y is not None:\n","            #### normalize\n","            x = F.normalize(x, p=2.0, dim=1)\n","            y = F.normalize(y, p=2.0, dim=1)\n","            ####\n","            edge_index = xy_dense_knn_matrix(x, y, self.k * self.dilation, relative_pos)\n","        else:\n","            #### normalize\n","            x = F.normalize(x, p=2.0, dim=1)\n","            ####\n","            edge_index = dense_knn_matrix(x, self.k * self.dilation, relative_pos)\n","        return self._dilated(edge_index)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"W_Si0Cude34c","executionInfo":{"status":"ok","timestamp":1660464573218,"user_tz":-540,"elapsed":3,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["# 2022.06.17-Changed for building ViG model\n","#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n","import torch\n","from torch import nn\n","from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n","\n","\n","##############################\n","#    Basic layers\n","##############################\n","def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n","    # activation layer\n","\n","    act = act.lower()\n","    if act == 'relu':\n","        layer = nn.ReLU(inplace)\n","    elif act == 'leakyrelu':\n","        layer = nn.LeakyReLU(neg_slope, inplace)\n","    elif act == 'prelu':\n","        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n","    elif act == 'gelu':\n","        layer = nn.GELU()\n","    elif act == 'hswish':\n","        layer = nn.Hardswish(inplace)\n","    else:\n","        raise NotImplementedError('activation layer [%s] is not found' % act)\n","    return layer\n","\n","\n","def norm_layer(norm, nc):\n","    # normalization layer 2d\n","    norm = norm.lower()\n","    if norm == 'batch':\n","        layer = nn.BatchNorm2d(nc, affine=True)\n","    elif norm == 'instance':\n","        layer = nn.InstanceNorm2d(nc, affine=False)\n","    else:\n","        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n","    return layer\n","\n","\n","class MLP(Seq):\n","    def __init__(self, channels, act='relu', norm=None, bias=True):\n","        m = []\n","        for i in range(1, len(channels)):\n","            m.append(Lin(channels[i - 1], channels[i], bias))\n","            if act is not None and act.lower() != 'none':\n","                m.append(act_layer(act))\n","            if norm is not None and norm.lower() != 'none':\n","                m.append(norm_layer(norm, channels[-1]))\n","        super(MLP, self).__init__(*m)\n","\n","\n","class BasicConv(Seq):\n","    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n","        m = []\n","        for i in range(1, len(channels)):\n","            m.append(Conv2d(channels[i - 1], channels[i], 1, bias=bias, groups=4))\n","            if norm is not None and norm.lower() != 'none':\n","                m.append(norm_layer(norm, channels[-1]))\n","            if act is not None and act.lower() != 'none':\n","                m.append(act_layer(act))\n","            if drop > 0:\n","                m.append(nn.Dropout2d(drop))\n","\n","        super(BasicConv, self).__init__(*m)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","def batched_index_select(x, idx):\n","    r\"\"\"fetches neighbors features from a given neighbor idx\n","\n","    Args:\n","        x (Tensor): input feature Tensor\n","                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n","        idx (Tensor): edge_idx\n","                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n","    Returns:\n","        Tensor: output neighbors features\n","            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n","    \"\"\"\n","    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n","    _, num_vertices, k = idx.shape\n","    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices_reduced\n","    idx = idx + idx_base\n","    idx = idx.contiguous().view(-1)\n","\n","    x = x.transpose(2, 1)\n","    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n","    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n","    return feature"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"cZDemV2Ae5mm","executionInfo":{"status":"ok","timestamp":1660464574802,"user_tz":-540,"elapsed":437,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["# 2022.06.17-Changed for building ViG model\n","#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n","import numpy as np\n","import torch\n","from torch import nn\n","# from .torch_nn import BasicConv, batched_index_select, act_layer\n","# from .torch_edge import DenseDilatedKnnGraph\n","# from .pos_embed import get_2d_relative_pos_embed\n","import torch.nn.functional as F\n","from timm.models.layers import DropPath\n","\n","\n","class MRConv2d(nn.Module):\n","    \"\"\"\n","    Max-Relative Graph Convolution (Paper: https://arxiv.org/abs/1904.03751) for dense data type\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n","        super(MRConv2d, self).__init__()\n","        self.nn = BasicConv([in_channels*2, out_channels], act, norm, bias)\n","\n","    def forward(self, x, edge_index, y=None):\n","        x_i = batched_index_select(x, edge_index[1])\n","        if y is not None:\n","            x_j = batched_index_select(y, edge_index[0])\n","        else:\n","            x_j = batched_index_select(x, edge_index[0])\n","        x_j, _ = torch.max(x_j - x_i, -1, keepdim=True)\n","        b, c, n, _ = x.shape\n","        x = torch.cat([x.unsqueeze(2), x_j.unsqueeze(2)], dim=2).reshape(b, 2 * c, n, _)\n","        return self.nn(x)\n","\n","\n","class EdgeConv2d(nn.Module):\n","    \"\"\"\n","    Edge convolution layer (with activation, batch normalization) for dense data type\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n","        super(EdgeConv2d, self).__init__()\n","        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n","\n","    def forward(self, x, edge_index, y=None):\n","        x_i = batched_index_select(x, edge_index[1])\n","        if y is not None:\n","            x_j = batched_index_select(y, edge_index[0])\n","        else:\n","            x_j = batched_index_select(x, edge_index[0])\n","        max_value, _ = torch.max(self.nn(torch.cat([x_i, x_j - x_i], dim=1)), -1, keepdim=True)\n","        return max_value\n","\n","\n","class GraphSAGE(nn.Module):\n","    \"\"\"\n","    GraphSAGE Graph Convolution (Paper: https://arxiv.org/abs/1706.02216) for dense data type\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n","        super(GraphSAGE, self).__init__()\n","        self.nn1 = BasicConv([in_channels, in_channels], act, norm, bias)\n","        self.nn2 = BasicConv([in_channels*2, out_channels], act, norm, bias)\n","\n","    def forward(self, x, edge_index, y=None):\n","        if y is not None:\n","            x_j = batched_index_select(y, edge_index[0])\n","        else:\n","            x_j = batched_index_select(x, edge_index[0])\n","        x_j, _ = torch.max(self.nn1(x_j), -1, keepdim=True)\n","        return self.nn2(torch.cat([x, x_j], dim=1))\n","\n","\n","class GINConv2d(nn.Module):\n","    \"\"\"\n","    GIN Graph Convolution (Paper: https://arxiv.org/abs/1810.00826) for dense data type\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n","        super(GINConv2d, self).__init__()\n","        self.nn = BasicConv([in_channels, out_channels], act, norm, bias)\n","        eps_init = 0.0\n","        self.eps = nn.Parameter(torch.Tensor([eps_init]))\n","\n","    def forward(self, x, edge_index, y=None):\n","        if y is not None:\n","            x_j = batched_index_select(y, edge_index[0])\n","        else:\n","            x_j = batched_index_select(x, edge_index[0])\n","        x_j = torch.sum(x_j, -1, keepdim=True)\n","        return self.nn((1 + self.eps) * x + x_j)\n","\n","\n","class GraphConv2d(nn.Module):\n","    \"\"\"\n","    Static graph convolution layer\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, conv='edge', act='relu', norm=None, bias=True):\n","        super(GraphConv2d, self).__init__()\n","        if conv == 'edge':\n","            self.gconv = EdgeConv2d(in_channels, out_channels, act, norm, bias)\n","        elif conv == 'mr':\n","            self.gconv = MRConv2d(in_channels, out_channels, act, norm, bias)\n","        elif conv == 'sage':\n","            self.gconv = GraphSAGE(in_channels, out_channels, act, norm, bias)\n","        elif conv == 'gin':\n","            self.gconv = GINConv2d(in_channels, out_channels, act, norm, bias)\n","        else:\n","            raise NotImplementedError('conv:{} is not supported'.format(conv))\n","\n","    def forward(self, x, edge_index, y=None):\n","        return self.gconv(x, edge_index, y)\n","\n","\n","class DyGraphConv2d(GraphConv2d):\n","    \"\"\"\n","    Dynamic graph convolution layer\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size=9, dilation=1, conv='edge', act='relu',\n","                 norm=None, bias=True, stochastic=False, epsilon=0.0, r=1):\n","        super(DyGraphConv2d, self).__init__(in_channels, out_channels, conv, act, norm, bias)\n","        self.k = kernel_size\n","        self.d = dilation\n","        self.r = r\n","        self.dilated_knn_graph = DenseDilatedKnnGraph(kernel_size, dilation, stochastic, epsilon)\n","\n","    def forward(self, x, relative_pos=None):\n","        B, C, H, W = x.shape\n","        y = None\n","        if self.r > 1:\n","            y = F.avg_pool2d(x, self.r, self.r)\n","            y = y.reshape(B, C, -1, 1).contiguous()            \n","        x = x.reshape(B, C, -1, 1).contiguous()\n","        edge_index = self.dilated_knn_graph(x, y, relative_pos)\n","        x = super(DyGraphConv2d, self).forward(x, edge_index, y)\n","        return x.reshape(B, -1, H, W).contiguous()\n","\n","\n","class Grapher(nn.Module):\n","    \"\"\"\n","    Grapher module with graph convolution and fc layers\n","    \"\"\"\n","    def __init__(self, in_channels, kernel_size=9, dilation=1, conv='edge', act='relu', norm=None,\n","                 bias=True,  stochastic=False, epsilon=0.0, r=1, n=196, drop_path=0.0, relative_pos=False):\n","        super(Grapher, self).__init__()\n","        self.channels = in_channels\n","        self.n = n\n","        self.r = r\n","        self.fc1 = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(in_channels),\n","        )\n","        self.graph_conv = DyGraphConv2d(in_channels, in_channels * 2, kernel_size, dilation, conv,\n","                              act, norm, bias, stochastic, epsilon, r)\n","        self.fc2 = nn.Sequential(\n","            nn.Conv2d(in_channels * 2, in_channels, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(in_channels),\n","        )\n","        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","        self.relative_pos = None\n","        if relative_pos:\n","            print('using relative_pos')\n","            relative_pos_tensor = torch.from_numpy(np.float32(get_2d_relative_pos_embed(in_channels,\n","                int(n**0.5)))).unsqueeze(0).unsqueeze(1)\n","            relative_pos_tensor = F.interpolate(\n","                    relative_pos_tensor, size=(n, n//(r*r)), mode='bicubic', align_corners=False)\n","            self.relative_pos = nn.Parameter(-relative_pos_tensor.squeeze(1), requires_grad=False)\n","\n","    def _get_relative_pos(self, relative_pos, H, W):\n","        if relative_pos is None or H * W == self.n:\n","            return relative_pos\n","        else:\n","            N = H * W\n","            N_reduced = N // (self.r * self.r)\n","            return F.interpolate(relative_pos.unsqueeze(0), size=(N, N_reduced), mode=\"bicubic\").squeeze(0)\n","\n","    def forward(self, x):\n","        _tmp = x\n","        x = self.fc1(x)\n","        B, C, H, W = x.shape\n","        relative_pos = self._get_relative_pos(self.relative_pos, H, W)\n","        x = self.graph_conv(x, relative_pos)\n","        x = self.fc2(x)\n","        x = self.drop_path(x) + _tmp\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"-_Pir36re7cW","executionInfo":{"status":"ok","timestamp":1660464576774,"user_tz":-540,"elapsed":800,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":["## 2022.06.17-Changed for building ViG model\n","#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n","#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Sequential as Seq\n","\n","from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n","from timm.models.helpers import load_pretrained\n","from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n","from timm.models.registry import register_model\n","\n","# from gcn_lib import Grapher, act_layer\n","\n","\n","def _cfg(url='', **kwargs):\n","    return {\n","        'url': url,\n","        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n","        'crop_pct': .9, 'interpolation': 'bicubic',\n","        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n","        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n","        **kwargs\n","    }\n","\n","\n","default_cfgs = {\n","    'vig_224_gelu': _cfg(\n","        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n","    ),\n","    'vig_b_224_gelu': _cfg(\n","        crop_pct=0.95, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n","    ),\n","}\n","\n","\n","class FFN(nn.Module):\n","    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n","        super().__init__()\n","        out_features = out_features or in_features\n","        hidden_features = hidden_features or in_features\n","        self.fc1 = nn.Sequential(\n","            nn.Conv2d(in_features, hidden_features, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(hidden_features),\n","        )\n","        self.act = act_layer(act)\n","        self.fc2 = nn.Sequential(\n","            nn.Conv2d(hidden_features, out_features, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(out_features),\n","        )\n","        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","\n","    def forward(self, x):\n","        shortcut = x\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.fc2(x)\n","        x = self.drop_path(x) + shortcut\n","        return x#.reshape(B, C, N, 1)\n","\n","\n","class Stem(nn.Module):\n","    \"\"\" Image to Visual Embedding\n","    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n","    \"\"\"\n","    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n","        super().__init__()        \n","        self.convs = nn.Sequential(\n","            nn.Conv2d(in_dim, out_dim//2, 3, stride=2, padding=1),\n","            nn.BatchNorm2d(out_dim//2),\n","            act_layer(act),\n","            nn.Conv2d(out_dim//2, out_dim, 3, stride=2, padding=1),\n","            nn.BatchNorm2d(out_dim),\n","            act_layer(act),\n","            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_dim),\n","        )\n","\n","    def forward(self, x):\n","        x = self.convs(x)\n","        return x\n","\n","\n","class Downsample(nn.Module):\n","    \"\"\" Convolution-based downsample\n","    \"\"\"\n","    def __init__(self, in_dim=3, out_dim=768):\n","        super().__init__()        \n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n","            nn.BatchNorm2d(out_dim),\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","\n","class DeepGCN(torch.nn.Module):\n","    def __init__(self, opt):\n","        super(DeepGCN, self).__init__()\n","        print(opt)\n","        k = opt.k\n","        act = opt.act\n","        norm = opt.norm\n","        bias = opt.bias\n","        epsilon = opt.epsilon\n","        stochastic = opt.use_stochastic\n","        conv = opt.conv\n","        emb_dims = opt.emb_dims\n","        drop_path = opt.drop_path\n","        \n","        blocks = opt.blocks\n","        self.n_blocks = sum(blocks)\n","        channels = opt.channels\n","        reduce_ratios = [4, 2, 1, 1]\n","        dpr = [x.item() for x in torch.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n","        num_knn = [int(x.item()) for x in torch.linspace(k, k, self.n_blocks)]  # number of knn's k\n","        max_dilation = 49 // max(num_knn)\n","        \n","        self.stem = Stem(out_dim=channels[0], act=act)\n","        self.pos_embed = nn.Parameter(torch.zeros(1, channels[0], 224//4, 224//4))\n","        HW = 224 // 4 * 224 // 4\n","\n","        self.backbone = nn.ModuleList([])\n","        idx = 0\n","        for i in range(len(blocks)):\n","            if i > 0:\n","                self.backbone.append(Downsample(channels[i-1], channels[i]))\n","                HW = HW // 4\n","            for j in range(blocks[i]):\n","                self.backbone += [\n","                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n","                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n","                                    relative_pos=True),\n","                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n","                         )]\n","                idx += 1\n","        self.backbone = Seq(*self.backbone)\n","\n","        self.prediction = Seq(nn.Conv2d(channels[-1], 1024, 1, bias=True),\n","                              nn.BatchNorm2d(1024),\n","                              act_layer(act),\n","                              nn.Dropout(opt.dropout),\n","                              nn.Conv2d(1024, opt.n_classes, 1, bias=True))\n","        self.model_init()\n","\n","    def model_init(self):\n","        for m in self.modules():\n","            if isinstance(m, torch.nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                m.weight.requires_grad = True\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","                    m.bias.requires_grad = True\n","\n","    def forward(self, inputs):\n","        x = self.stem(inputs) + self.pos_embed\n","        B, C, H, W = x.shape\n","        for i in range(len(self.backbone)):\n","            x = self.backbone[i](x)\n","\n","        x = F.adaptive_avg_pool2d(x, 1)\n","        return self.prediction(x).squeeze(-1).squeeze(-1)\n","\n","\n","@register_model\n","def pvig_ti_224(pretrained=False, **kwargs):\n","    class OptInit:\n","        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n","            self.k = 9 # neighbor num (default:9)\n","            self.conv = 'mr' # graph conv layer {edge, mr}\n","            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n","            self.norm = 'batch' # batch or instance normalization {batch, instance}\n","            self.bias = True # bias of conv layer True or False\n","            self.dropout = 0.0 # dropout rate\n","            self.use_dilation = True # use dilated knn or not\n","            self.epsilon = 0.2 # stochastic epsilon for gcn\n","            self.use_stochastic = False # stochastic for gcn, True or False\n","            self.drop_path = drop_path_rate\n","            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n","            self.channels = [48, 96, 240, 384] # number of channels of deep features\n","            self.n_classes = num_classes # Dimension of out_channels\n","            self.emb_dims = 1024 # Dimension of embeddings\n","\n","    opt = OptInit(**kwargs)\n","    model = DeepGCN(opt)\n","    model.default_cfg = default_cfgs['vig_224_gelu']\n","    return model\n","\n","\n","@register_model\n","def pvig_s_224(pretrained=False, **kwargs):\n","    class OptInit:\n","        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n","            self.k = 9 # neighbor num (default:9)\n","            self.conv = 'mr' # graph conv layer {edge, mr}\n","            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n","            self.norm = 'batch' # batch or instance normalization {batch, instance}\n","            self.bias = True # bias of conv layer True or False\n","            self.dropout = 0.0 # dropout rate\n","            self.use_dilation = True # use dilated knn or not\n","            self.epsilon = 0.2 # stochastic epsilon for gcn\n","            self.use_stochastic = False # stochastic for gcn, True or False\n","            self.drop_path = drop_path_rate\n","            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n","            self.channels = [80, 160, 400, 640] # number of channels of deep features\n","            self.n_classes = num_classes # Dimension of out_channels\n","            self.emb_dims = 1024 # Dimension of embeddings\n","\n","    opt = OptInit(**kwargs)\n","    model = DeepGCN(opt)\n","    model.default_cfg = default_cfgs['vig_224_gelu']\n","    return model\n","\n","\n","@register_model\n","def pvig_m_224(pretrained=False, **kwargs):\n","    class OptInit:\n","        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n","            self.k = 9 # neighbor num (default:9)\n","            self.conv = 'mr' # graph conv layer {edge, mr}\n","            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n","            self.norm = 'batch' # batch or instance normalization {batch, instance}\n","            self.bias = True # bias of conv layer True or False\n","            self.dropout = 0.0 # dropout rate\n","            self.use_dilation = True # use dilated knn or not\n","            self.epsilon = 0.2 # stochastic epsilon for gcn\n","            self.use_stochastic = False # stochastic for gcn, True or False\n","            self.drop_path = drop_path_rate\n","            self.blocks = [2,2,16,2] # number of basic blocks in the backbone\n","            self.channels = [96, 192, 384, 768] # number of channels of deep features\n","            self.n_classes = num_classes # Dimension of out_channels\n","            self.emb_dims = 1024 # Dimension of embeddings\n","\n","    opt = OptInit(**kwargs)\n","    model = DeepGCN(opt)\n","    model.default_cfg = default_cfgs['vig_224_gelu']\n","    return model\n","\n","\n","@register_model\n","def pvig_b_224(pretrained=False, **kwargs):\n","    class OptInit:\n","        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n","            self.k = 9 # neighbor num (default:9)\n","            self.conv = 'mr' # graph conv layer {edge, mr}\n","            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n","            self.norm = 'batch' # batch or instance normalization {batch, instance}\n","            self.bias = True # bias of conv layer True or False\n","            self.dropout = 0.0 # dropout rate\n","            self.use_dilation = True # use dilated knn or not\n","            self.epsilon = 0.2 # stochastic epsilon for gcn\n","            self.use_stochastic = False # stochastic for gcn, True or False\n","            self.drop_path = drop_path_rate\n","            self.blocks = [2,2,18,2] # number of basic blocks in the backbone\n","            self.channels = [128, 256, 512, 1024] # number of channels of deep features\n","            self.n_classes = num_classes # Dimension of out_channels\n","            self.emb_dims = 1024 # Dimension of embeddings\n","\n","    opt = OptInit(**kwargs)\n","    model = DeepGCN(opt)\n","    model.default_cfg = default_cfgs['vig_b_224_gelu']\n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wAuVZtJe89n","outputId":"3296b5f3-5191-4c92-b331-e908aee7a7bd","executionInfo":{"status":"ok","timestamp":1660464580514,"user_tz":-540,"elapsed":2811,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.pvig_b_224.<locals>.OptInit object at 0x7ffa440d8f90>\n","using relative_pos\n","using relative_pos\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]},{"output_type":"stream","name":"stdout","text":["using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n","using relative_pos\n"]}],"source":["model = pvig_b_224()\n","model = model.to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.95)\n","criterion = nn.CrossEntropyLoss()\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4369fRxe-tf","outputId":"b8239f72-c652-48eb-ee6c-5e48873206d2","executionInfo":{"status":"ok","timestamp":1660464584712,"user_tz":-540,"elapsed":3076,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           1,792\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              GELU-3         [-1, 64, 112, 112]               0\n","            Conv2d-4          [-1, 128, 56, 56]          73,856\n","       BatchNorm2d-5          [-1, 128, 56, 56]             256\n","              GELU-6          [-1, 128, 56, 56]               0\n","            Conv2d-7          [-1, 128, 56, 56]         147,584\n","       BatchNorm2d-8          [-1, 128, 56, 56]             256\n","              Stem-9          [-1, 128, 56, 56]               0\n","           Conv2d-10          [-1, 128, 56, 56]          16,512\n","      BatchNorm2d-11          [-1, 128, 56, 56]             256\n","     DenseDilated-12           [-1, 2, 3136, 9]               0\n","DenseDilatedKnnGraph-13           [-1, 2, 3136, 9]               0\n","           Conv2d-14         [-1, 256, 3136, 1]          16,640\n","      BatchNorm2d-15         [-1, 256, 3136, 1]             512\n","             GELU-16         [-1, 256, 3136, 1]               0\n","         MRConv2d-17         [-1, 256, 3136, 1]               0\n","    DyGraphConv2d-18          [-1, 256, 56, 56]               0\n","           Conv2d-19          [-1, 128, 56, 56]          32,896\n","      BatchNorm2d-20          [-1, 128, 56, 56]             256\n","         Identity-21          [-1, 128, 56, 56]               0\n","          Grapher-22          [-1, 128, 56, 56]               0\n","           Conv2d-23          [-1, 512, 56, 56]          66,048\n","      BatchNorm2d-24          [-1, 512, 56, 56]           1,024\n","             GELU-25          [-1, 512, 56, 56]               0\n","           Conv2d-26          [-1, 128, 56, 56]          65,664\n","      BatchNorm2d-27          [-1, 128, 56, 56]             256\n","         Identity-28          [-1, 128, 56, 56]               0\n","              FFN-29          [-1, 128, 56, 56]               0\n","           Conv2d-30          [-1, 128, 56, 56]          16,512\n","      BatchNorm2d-31          [-1, 128, 56, 56]             256\n","     DenseDilated-32           [-1, 2, 3136, 9]               0\n","DenseDilatedKnnGraph-33           [-1, 2, 3136, 9]               0\n","           Conv2d-34         [-1, 256, 3136, 1]          16,640\n","      BatchNorm2d-35         [-1, 256, 3136, 1]             512\n","             GELU-36         [-1, 256, 3136, 1]               0\n","         MRConv2d-37         [-1, 256, 3136, 1]               0\n","    DyGraphConv2d-38          [-1, 256, 56, 56]               0\n","           Conv2d-39          [-1, 128, 56, 56]          32,896\n","      BatchNorm2d-40          [-1, 128, 56, 56]             256\n","         Identity-41          [-1, 128, 56, 56]               0\n","          Grapher-42          [-1, 128, 56, 56]               0\n","           Conv2d-43          [-1, 512, 56, 56]          66,048\n","      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n","             GELU-45          [-1, 512, 56, 56]               0\n","           Conv2d-46          [-1, 128, 56, 56]          65,664\n","      BatchNorm2d-47          [-1, 128, 56, 56]             256\n","         Identity-48          [-1, 128, 56, 56]               0\n","              FFN-49          [-1, 128, 56, 56]               0\n","           Conv2d-50          [-1, 256, 28, 28]         295,168\n","      BatchNorm2d-51          [-1, 256, 28, 28]             512\n","       Downsample-52          [-1, 256, 28, 28]               0\n","           Conv2d-53          [-1, 256, 28, 28]          65,792\n","      BatchNorm2d-54          [-1, 256, 28, 28]             512\n","     DenseDilated-55            [-1, 2, 784, 9]               0\n","DenseDilatedKnnGraph-56            [-1, 2, 784, 9]               0\n","           Conv2d-57          [-1, 512, 784, 1]          66,048\n","      BatchNorm2d-58          [-1, 512, 784, 1]           1,024\n","             GELU-59          [-1, 512, 784, 1]               0\n","         MRConv2d-60          [-1, 512, 784, 1]               0\n","    DyGraphConv2d-61          [-1, 512, 28, 28]               0\n","           Conv2d-62          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-63          [-1, 256, 28, 28]             512\n","         Identity-64          [-1, 256, 28, 28]               0\n","          Grapher-65          [-1, 256, 28, 28]               0\n","           Conv2d-66         [-1, 1024, 28, 28]         263,168\n","      BatchNorm2d-67         [-1, 1024, 28, 28]           2,048\n","             GELU-68         [-1, 1024, 28, 28]               0\n","           Conv2d-69          [-1, 256, 28, 28]         262,400\n","      BatchNorm2d-70          [-1, 256, 28, 28]             512\n","         Identity-71          [-1, 256, 28, 28]               0\n","              FFN-72          [-1, 256, 28, 28]               0\n","           Conv2d-73          [-1, 256, 28, 28]          65,792\n","      BatchNorm2d-74          [-1, 256, 28, 28]             512\n","     DenseDilated-75            [-1, 2, 784, 9]               0\n","DenseDilatedKnnGraph-76            [-1, 2, 784, 9]               0\n","           Conv2d-77          [-1, 512, 784, 1]          66,048\n","      BatchNorm2d-78          [-1, 512, 784, 1]           1,024\n","             GELU-79          [-1, 512, 784, 1]               0\n","         MRConv2d-80          [-1, 512, 784, 1]               0\n","    DyGraphConv2d-81          [-1, 512, 28, 28]               0\n","           Conv2d-82          [-1, 256, 28, 28]         131,328\n","      BatchNorm2d-83          [-1, 256, 28, 28]             512\n","         Identity-84          [-1, 256, 28, 28]               0\n","          Grapher-85          [-1, 256, 28, 28]               0\n","           Conv2d-86         [-1, 1024, 28, 28]         263,168\n","      BatchNorm2d-87         [-1, 1024, 28, 28]           2,048\n","             GELU-88         [-1, 1024, 28, 28]               0\n","           Conv2d-89          [-1, 256, 28, 28]         262,400\n","      BatchNorm2d-90          [-1, 256, 28, 28]             512\n","         Identity-91          [-1, 256, 28, 28]               0\n","              FFN-92          [-1, 256, 28, 28]               0\n","           Conv2d-93          [-1, 512, 14, 14]       1,180,160\n","      BatchNorm2d-94          [-1, 512, 14, 14]           1,024\n","       Downsample-95          [-1, 512, 14, 14]               0\n","           Conv2d-96          [-1, 512, 14, 14]         262,656\n","      BatchNorm2d-97          [-1, 512, 14, 14]           1,024\n","     DenseDilated-98            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-99            [-1, 2, 196, 9]               0\n","          Conv2d-100         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-101         [-1, 1024, 196, 1]           2,048\n","            GELU-102         [-1, 1024, 196, 1]               0\n","        MRConv2d-103         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-104         [-1, 1024, 14, 14]               0\n","          Conv2d-105          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-106          [-1, 512, 14, 14]           1,024\n","        Identity-107          [-1, 512, 14, 14]               0\n","         Grapher-108          [-1, 512, 14, 14]               0\n","          Conv2d-109         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-110         [-1, 2048, 14, 14]           4,096\n","            GELU-111         [-1, 2048, 14, 14]               0\n","          Conv2d-112          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-113          [-1, 512, 14, 14]           1,024\n","        Identity-114          [-1, 512, 14, 14]               0\n","             FFN-115          [-1, 512, 14, 14]               0\n","          Conv2d-116          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-117          [-1, 512, 14, 14]           1,024\n","    DenseDilated-118            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-119            [-1, 2, 196, 9]               0\n","          Conv2d-120         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-121         [-1, 1024, 196, 1]           2,048\n","            GELU-122         [-1, 1024, 196, 1]               0\n","        MRConv2d-123         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-124         [-1, 1024, 14, 14]               0\n","          Conv2d-125          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-126          [-1, 512, 14, 14]           1,024\n","        Identity-127          [-1, 512, 14, 14]               0\n","         Grapher-128          [-1, 512, 14, 14]               0\n","          Conv2d-129         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-130         [-1, 2048, 14, 14]           4,096\n","            GELU-131         [-1, 2048, 14, 14]               0\n","          Conv2d-132          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-133          [-1, 512, 14, 14]           1,024\n","        Identity-134          [-1, 512, 14, 14]               0\n","             FFN-135          [-1, 512, 14, 14]               0\n","          Conv2d-136          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-137          [-1, 512, 14, 14]           1,024\n","    DenseDilated-138            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-139            [-1, 2, 196, 9]               0\n","          Conv2d-140         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-141         [-1, 1024, 196, 1]           2,048\n","            GELU-142         [-1, 1024, 196, 1]               0\n","        MRConv2d-143         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-144         [-1, 1024, 14, 14]               0\n","          Conv2d-145          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-146          [-1, 512, 14, 14]           1,024\n","        Identity-147          [-1, 512, 14, 14]               0\n","         Grapher-148          [-1, 512, 14, 14]               0\n","          Conv2d-149         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-150         [-1, 2048, 14, 14]           4,096\n","            GELU-151         [-1, 2048, 14, 14]               0\n","          Conv2d-152          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-153          [-1, 512, 14, 14]           1,024\n","        Identity-154          [-1, 512, 14, 14]               0\n","             FFN-155          [-1, 512, 14, 14]               0\n","          Conv2d-156          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-157          [-1, 512, 14, 14]           1,024\n","    DenseDilated-158            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-159            [-1, 2, 196, 9]               0\n","          Conv2d-160         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-161         [-1, 1024, 196, 1]           2,048\n","            GELU-162         [-1, 1024, 196, 1]               0\n","        MRConv2d-163         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-164         [-1, 1024, 14, 14]               0\n","          Conv2d-165          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-166          [-1, 512, 14, 14]           1,024\n","        Identity-167          [-1, 512, 14, 14]               0\n","         Grapher-168          [-1, 512, 14, 14]               0\n","          Conv2d-169         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-170         [-1, 2048, 14, 14]           4,096\n","            GELU-171         [-1, 2048, 14, 14]               0\n","          Conv2d-172          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-173          [-1, 512, 14, 14]           1,024\n","        Identity-174          [-1, 512, 14, 14]               0\n","             FFN-175          [-1, 512, 14, 14]               0\n","          Conv2d-176          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-177          [-1, 512, 14, 14]           1,024\n","    DenseDilated-178            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-179            [-1, 2, 196, 9]               0\n","          Conv2d-180         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-181         [-1, 1024, 196, 1]           2,048\n","            GELU-182         [-1, 1024, 196, 1]               0\n","        MRConv2d-183         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-184         [-1, 1024, 14, 14]               0\n","          Conv2d-185          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-186          [-1, 512, 14, 14]           1,024\n","        Identity-187          [-1, 512, 14, 14]               0\n","         Grapher-188          [-1, 512, 14, 14]               0\n","          Conv2d-189         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-190         [-1, 2048, 14, 14]           4,096\n","            GELU-191         [-1, 2048, 14, 14]               0\n","          Conv2d-192          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-193          [-1, 512, 14, 14]           1,024\n","        Identity-194          [-1, 512, 14, 14]               0\n","             FFN-195          [-1, 512, 14, 14]               0\n","          Conv2d-196          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-197          [-1, 512, 14, 14]           1,024\n","    DenseDilated-198            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-199            [-1, 2, 196, 9]               0\n","          Conv2d-200         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-201         [-1, 1024, 196, 1]           2,048\n","            GELU-202         [-1, 1024, 196, 1]               0\n","        MRConv2d-203         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-204         [-1, 1024, 14, 14]               0\n","          Conv2d-205          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-206          [-1, 512, 14, 14]           1,024\n","        Identity-207          [-1, 512, 14, 14]               0\n","         Grapher-208          [-1, 512, 14, 14]               0\n","          Conv2d-209         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-210         [-1, 2048, 14, 14]           4,096\n","            GELU-211         [-1, 2048, 14, 14]               0\n","          Conv2d-212          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-213          [-1, 512, 14, 14]           1,024\n","        Identity-214          [-1, 512, 14, 14]               0\n","             FFN-215          [-1, 512, 14, 14]               0\n","          Conv2d-216          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-217          [-1, 512, 14, 14]           1,024\n","    DenseDilated-218            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-219            [-1, 2, 196, 9]               0\n","          Conv2d-220         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-221         [-1, 1024, 196, 1]           2,048\n","            GELU-222         [-1, 1024, 196, 1]               0\n","        MRConv2d-223         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-224         [-1, 1024, 14, 14]               0\n","          Conv2d-225          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-226          [-1, 512, 14, 14]           1,024\n","        Identity-227          [-1, 512, 14, 14]               0\n","         Grapher-228          [-1, 512, 14, 14]               0\n","          Conv2d-229         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-230         [-1, 2048, 14, 14]           4,096\n","            GELU-231         [-1, 2048, 14, 14]               0\n","          Conv2d-232          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-233          [-1, 512, 14, 14]           1,024\n","        Identity-234          [-1, 512, 14, 14]               0\n","             FFN-235          [-1, 512, 14, 14]               0\n","          Conv2d-236          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-237          [-1, 512, 14, 14]           1,024\n","    DenseDilated-238            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-239            [-1, 2, 196, 9]               0\n","          Conv2d-240         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-241         [-1, 1024, 196, 1]           2,048\n","            GELU-242         [-1, 1024, 196, 1]               0\n","        MRConv2d-243         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-244         [-1, 1024, 14, 14]               0\n","          Conv2d-245          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-246          [-1, 512, 14, 14]           1,024\n","        Identity-247          [-1, 512, 14, 14]               0\n","         Grapher-248          [-1, 512, 14, 14]               0\n","          Conv2d-249         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-250         [-1, 2048, 14, 14]           4,096\n","            GELU-251         [-1, 2048, 14, 14]               0\n","          Conv2d-252          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-253          [-1, 512, 14, 14]           1,024\n","        Identity-254          [-1, 512, 14, 14]               0\n","             FFN-255          [-1, 512, 14, 14]               0\n","          Conv2d-256          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-257          [-1, 512, 14, 14]           1,024\n","    DenseDilated-258            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-259            [-1, 2, 196, 9]               0\n","          Conv2d-260         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-261         [-1, 1024, 196, 1]           2,048\n","            GELU-262         [-1, 1024, 196, 1]               0\n","        MRConv2d-263         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-264         [-1, 1024, 14, 14]               0\n","          Conv2d-265          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-266          [-1, 512, 14, 14]           1,024\n","        Identity-267          [-1, 512, 14, 14]               0\n","         Grapher-268          [-1, 512, 14, 14]               0\n","          Conv2d-269         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-270         [-1, 2048, 14, 14]           4,096\n","            GELU-271         [-1, 2048, 14, 14]               0\n","          Conv2d-272          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-273          [-1, 512, 14, 14]           1,024\n","        Identity-274          [-1, 512, 14, 14]               0\n","             FFN-275          [-1, 512, 14, 14]               0\n","          Conv2d-276          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-277          [-1, 512, 14, 14]           1,024\n","    DenseDilated-278            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-279            [-1, 2, 196, 9]               0\n","          Conv2d-280         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-281         [-1, 1024, 196, 1]           2,048\n","            GELU-282         [-1, 1024, 196, 1]               0\n","        MRConv2d-283         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-284         [-1, 1024, 14, 14]               0\n","          Conv2d-285          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-286          [-1, 512, 14, 14]           1,024\n","        Identity-287          [-1, 512, 14, 14]               0\n","         Grapher-288          [-1, 512, 14, 14]               0\n","          Conv2d-289         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-290         [-1, 2048, 14, 14]           4,096\n","            GELU-291         [-1, 2048, 14, 14]               0\n","          Conv2d-292          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-293          [-1, 512, 14, 14]           1,024\n","        Identity-294          [-1, 512, 14, 14]               0\n","             FFN-295          [-1, 512, 14, 14]               0\n","          Conv2d-296          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-297          [-1, 512, 14, 14]           1,024\n","    DenseDilated-298            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-299            [-1, 2, 196, 9]               0\n","          Conv2d-300         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-301         [-1, 1024, 196, 1]           2,048\n","            GELU-302         [-1, 1024, 196, 1]               0\n","        MRConv2d-303         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-304         [-1, 1024, 14, 14]               0\n","          Conv2d-305          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-306          [-1, 512, 14, 14]           1,024\n","        Identity-307          [-1, 512, 14, 14]               0\n","         Grapher-308          [-1, 512, 14, 14]               0\n","          Conv2d-309         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-310         [-1, 2048, 14, 14]           4,096\n","            GELU-311         [-1, 2048, 14, 14]               0\n","          Conv2d-312          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-313          [-1, 512, 14, 14]           1,024\n","        Identity-314          [-1, 512, 14, 14]               0\n","             FFN-315          [-1, 512, 14, 14]               0\n","          Conv2d-316          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-317          [-1, 512, 14, 14]           1,024\n","    DenseDilated-318            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-319            [-1, 2, 196, 9]               0\n","          Conv2d-320         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-321         [-1, 1024, 196, 1]           2,048\n","            GELU-322         [-1, 1024, 196, 1]               0\n","        MRConv2d-323         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-324         [-1, 1024, 14, 14]               0\n","          Conv2d-325          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-326          [-1, 512, 14, 14]           1,024\n","        Identity-327          [-1, 512, 14, 14]               0\n","         Grapher-328          [-1, 512, 14, 14]               0\n","          Conv2d-329         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-330         [-1, 2048, 14, 14]           4,096\n","            GELU-331         [-1, 2048, 14, 14]               0\n","          Conv2d-332          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-333          [-1, 512, 14, 14]           1,024\n","        Identity-334          [-1, 512, 14, 14]               0\n","             FFN-335          [-1, 512, 14, 14]               0\n","          Conv2d-336          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-337          [-1, 512, 14, 14]           1,024\n","    DenseDilated-338            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-339            [-1, 2, 196, 9]               0\n","          Conv2d-340         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-341         [-1, 1024, 196, 1]           2,048\n","            GELU-342         [-1, 1024, 196, 1]               0\n","        MRConv2d-343         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-344         [-1, 1024, 14, 14]               0\n","          Conv2d-345          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-346          [-1, 512, 14, 14]           1,024\n","        Identity-347          [-1, 512, 14, 14]               0\n","         Grapher-348          [-1, 512, 14, 14]               0\n","          Conv2d-349         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-350         [-1, 2048, 14, 14]           4,096\n","            GELU-351         [-1, 2048, 14, 14]               0\n","          Conv2d-352          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-353          [-1, 512, 14, 14]           1,024\n","        Identity-354          [-1, 512, 14, 14]               0\n","             FFN-355          [-1, 512, 14, 14]               0\n","          Conv2d-356          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-357          [-1, 512, 14, 14]           1,024\n","    DenseDilated-358            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-359            [-1, 2, 196, 9]               0\n","          Conv2d-360         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-361         [-1, 1024, 196, 1]           2,048\n","            GELU-362         [-1, 1024, 196, 1]               0\n","        MRConv2d-363         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-364         [-1, 1024, 14, 14]               0\n","          Conv2d-365          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-366          [-1, 512, 14, 14]           1,024\n","        Identity-367          [-1, 512, 14, 14]               0\n","         Grapher-368          [-1, 512, 14, 14]               0\n","          Conv2d-369         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-370         [-1, 2048, 14, 14]           4,096\n","            GELU-371         [-1, 2048, 14, 14]               0\n","          Conv2d-372          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-373          [-1, 512, 14, 14]           1,024\n","        Identity-374          [-1, 512, 14, 14]               0\n","             FFN-375          [-1, 512, 14, 14]               0\n","          Conv2d-376          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-377          [-1, 512, 14, 14]           1,024\n","    DenseDilated-378            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-379            [-1, 2, 196, 9]               0\n","          Conv2d-380         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-381         [-1, 1024, 196, 1]           2,048\n","            GELU-382         [-1, 1024, 196, 1]               0\n","        MRConv2d-383         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-384         [-1, 1024, 14, 14]               0\n","          Conv2d-385          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-386          [-1, 512, 14, 14]           1,024\n","        Identity-387          [-1, 512, 14, 14]               0\n","         Grapher-388          [-1, 512, 14, 14]               0\n","          Conv2d-389         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-390         [-1, 2048, 14, 14]           4,096\n","            GELU-391         [-1, 2048, 14, 14]               0\n","          Conv2d-392          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-393          [-1, 512, 14, 14]           1,024\n","        Identity-394          [-1, 512, 14, 14]               0\n","             FFN-395          [-1, 512, 14, 14]               0\n","          Conv2d-396          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-397          [-1, 512, 14, 14]           1,024\n","    DenseDilated-398            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-399            [-1, 2, 196, 9]               0\n","          Conv2d-400         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-401         [-1, 1024, 196, 1]           2,048\n","            GELU-402         [-1, 1024, 196, 1]               0\n","        MRConv2d-403         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-404         [-1, 1024, 14, 14]               0\n","          Conv2d-405          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-406          [-1, 512, 14, 14]           1,024\n","        Identity-407          [-1, 512, 14, 14]               0\n","         Grapher-408          [-1, 512, 14, 14]               0\n","          Conv2d-409         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-410         [-1, 2048, 14, 14]           4,096\n","            GELU-411         [-1, 2048, 14, 14]               0\n","          Conv2d-412          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-413          [-1, 512, 14, 14]           1,024\n","        Identity-414          [-1, 512, 14, 14]               0\n","             FFN-415          [-1, 512, 14, 14]               0\n","          Conv2d-416          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-417          [-1, 512, 14, 14]           1,024\n","    DenseDilated-418            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-419            [-1, 2, 196, 9]               0\n","          Conv2d-420         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-421         [-1, 1024, 196, 1]           2,048\n","            GELU-422         [-1, 1024, 196, 1]               0\n","        MRConv2d-423         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-424         [-1, 1024, 14, 14]               0\n","          Conv2d-425          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-426          [-1, 512, 14, 14]           1,024\n","        Identity-427          [-1, 512, 14, 14]               0\n","         Grapher-428          [-1, 512, 14, 14]               0\n","          Conv2d-429         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-430         [-1, 2048, 14, 14]           4,096\n","            GELU-431         [-1, 2048, 14, 14]               0\n","          Conv2d-432          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-433          [-1, 512, 14, 14]           1,024\n","        Identity-434          [-1, 512, 14, 14]               0\n","             FFN-435          [-1, 512, 14, 14]               0\n","          Conv2d-436          [-1, 512, 14, 14]         262,656\n","     BatchNorm2d-437          [-1, 512, 14, 14]           1,024\n","    DenseDilated-438            [-1, 2, 196, 9]               0\n","DenseDilatedKnnGraph-439            [-1, 2, 196, 9]               0\n","          Conv2d-440         [-1, 1024, 196, 1]         263,168\n","     BatchNorm2d-441         [-1, 1024, 196, 1]           2,048\n","            GELU-442         [-1, 1024, 196, 1]               0\n","        MRConv2d-443         [-1, 1024, 196, 1]               0\n","   DyGraphConv2d-444         [-1, 1024, 14, 14]               0\n","          Conv2d-445          [-1, 512, 14, 14]         524,800\n","     BatchNorm2d-446          [-1, 512, 14, 14]           1,024\n","        Identity-447          [-1, 512, 14, 14]               0\n","         Grapher-448          [-1, 512, 14, 14]               0\n","          Conv2d-449         [-1, 2048, 14, 14]       1,050,624\n","     BatchNorm2d-450         [-1, 2048, 14, 14]           4,096\n","            GELU-451         [-1, 2048, 14, 14]               0\n","          Conv2d-452          [-1, 512, 14, 14]       1,049,088\n","     BatchNorm2d-453          [-1, 512, 14, 14]           1,024\n","        Identity-454          [-1, 512, 14, 14]               0\n","             FFN-455          [-1, 512, 14, 14]               0\n","          Conv2d-456           [-1, 1024, 7, 7]       4,719,616\n","     BatchNorm2d-457           [-1, 1024, 7, 7]           2,048\n","      Downsample-458           [-1, 1024, 7, 7]               0\n","          Conv2d-459           [-1, 1024, 7, 7]       1,049,600\n","     BatchNorm2d-460           [-1, 1024, 7, 7]           2,048\n","    DenseDilated-461             [-1, 2, 49, 9]               0\n","DenseDilatedKnnGraph-462             [-1, 2, 49, 9]               0\n","          Conv2d-463          [-1, 2048, 49, 1]       1,050,624\n","     BatchNorm2d-464          [-1, 2048, 49, 1]           4,096\n","            GELU-465          [-1, 2048, 49, 1]               0\n","        MRConv2d-466          [-1, 2048, 49, 1]               0\n","   DyGraphConv2d-467           [-1, 2048, 7, 7]               0\n","          Conv2d-468           [-1, 1024, 7, 7]       2,098,176\n","     BatchNorm2d-469           [-1, 1024, 7, 7]           2,048\n","        Identity-470           [-1, 1024, 7, 7]               0\n","         Grapher-471           [-1, 1024, 7, 7]               0\n","          Conv2d-472           [-1, 4096, 7, 7]       4,198,400\n","     BatchNorm2d-473           [-1, 4096, 7, 7]           8,192\n","            GELU-474           [-1, 4096, 7, 7]               0\n","          Conv2d-475           [-1, 1024, 7, 7]       4,195,328\n","     BatchNorm2d-476           [-1, 1024, 7, 7]           2,048\n","        Identity-477           [-1, 1024, 7, 7]               0\n","             FFN-478           [-1, 1024, 7, 7]               0\n","          Conv2d-479           [-1, 1024, 7, 7]       1,049,600\n","     BatchNorm2d-480           [-1, 1024, 7, 7]           2,048\n","    DenseDilated-481             [-1, 2, 49, 9]               0\n","DenseDilatedKnnGraph-482             [-1, 2, 49, 9]               0\n","          Conv2d-483          [-1, 2048, 49, 1]       1,050,624\n","     BatchNorm2d-484          [-1, 2048, 49, 1]           4,096\n","            GELU-485          [-1, 2048, 49, 1]               0\n","        MRConv2d-486          [-1, 2048, 49, 1]               0\n","   DyGraphConv2d-487           [-1, 2048, 7, 7]               0\n","          Conv2d-488           [-1, 1024, 7, 7]       2,098,176\n","     BatchNorm2d-489           [-1, 1024, 7, 7]           2,048\n","        Identity-490           [-1, 1024, 7, 7]               0\n","         Grapher-491           [-1, 1024, 7, 7]               0\n","          Conv2d-492           [-1, 4096, 7, 7]       4,198,400\n","     BatchNorm2d-493           [-1, 4096, 7, 7]           8,192\n","            GELU-494           [-1, 4096, 7, 7]               0\n","          Conv2d-495           [-1, 1024, 7, 7]       4,195,328\n","     BatchNorm2d-496           [-1, 1024, 7, 7]           2,048\n","        Identity-497           [-1, 1024, 7, 7]               0\n","             FFN-498           [-1, 1024, 7, 7]               0\n","          Conv2d-499           [-1, 1024, 1, 1]       1,049,600\n","     BatchNorm2d-500           [-1, 1024, 1, 1]           2,048\n","            GELU-501           [-1, 1024, 1, 1]               0\n","         Dropout-502           [-1, 1024, 1, 1]               0\n","          Conv2d-503           [-1, 1000, 1, 1]       1,025,000\n","================================================================\n","Total params: 92,578,920\n","Trainable params: 92,578,920\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 807.48\n","Params size (MB): 353.16\n","Estimated Total Size (MB): 1161.21\n","----------------------------------------------------------------\n"]}],"source":["from torchsummary import summary\n","\n","summary(model, (3,224,224))"]},{"cell_type":"markdown","metadata":{"id":"isMpq-8YfGyS"},"source":["## Fruit_quality 데이터셋 실험"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TM7ErW01fBHE","outputId":"a8694fa2-5b4c-4f48-ef7a-b57585e39b8f","executionInfo":{"status":"ok","timestamp":1660464590370,"user_tz":-540,"elapsed":1072,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["14750\n"]}],"source":["# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n","# 검증을 위한 일반화\n","# from email.mime import image\n","\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","\n","data_dir = '/content/drive/MyDrive/Data/fruit_quality'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'test']}\n","print(len(image_datasets['train']))\n","# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n","#                                              shuffle=True, num_workers=0)\n","#               for x in ['train', 'test']}\n","# dataset_sizes = {x: len(image_datasets[x]) for x in ['train','test']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"dnJWvjb-fLWW"},"source":["## train set에서 val set을 생성 (20%)\n","<!-- ##### train set이 너무 커서 시간, 용량을 많이 잡아먹음. Test set에서 val set을 나누기로 함 -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJKTua3jfIlj"},"outputs":[],"source":["# split the indices of test0_ds into two groups\n","# there aren't validation data in STL10 dataset, so make validation data\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# StratifiedShuffleSplit sample the data in same proportion of labels\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","indices = list(range(len(image_datasets['train'])))          # test set으로부터 나누고싶으면 'train' -> 'test'으로 변경\n","y_train0 = [y for _, y in image_datasets['train']]\n","\n"]},{"cell_type":"code","source":["for train_index, val_index in sss.split(indices, y_train0):\n","    print('train:', train_index, 'val:', val_index)\n","    print(len(train_index), len(val_index))"],"metadata":{"id":"cAjiegnFaXzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFYFk3Y0fNJU"},"outputs":[],"source":["from torch.utils.data import Subset\n","\n","train_ds = Subset(image_datasets['train'], train_index)\n","val_ds = Subset(image_datasets['train'], val_index)\n","\n","train_size = len(train_ds)\n","val_size = len(val_ds)\n","test_size = len(image_datasets['test'])\n","\n","print(train_size, val_size, test_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3UG6BD6fOoD"},"outputs":[],"source":["# val_ds, test_ds의 클래스별 이미지수 확인\n","# count the number of images per class in val_ds and test_ds \n","import collections\n","import numpy as np\n","\n","y_train = [y for _, y in train_ds]\n","y_val = [y for _, y in val_ds]\n","\n","counter_train = collections.Counter(y_train)\n","counter_val = collections.Counter(y_val)\n","print(counter_train)\n","print(counter_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLqOVF5QfP6G"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=64,shuffle=True, num_workers=0)\n","val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=64,shuffle=True, num_workers=0)\n","test_dataloader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=64,shuffle=True, num_workers=0)                           "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PhCISUufRLC"},"outputs":[],"source":["# transform 된 배치 이미지 시각화\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n","\n","\n","# 학습 데이터의 배치를 얻습니다.\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# 배치로부터 격자 형태의 이미지를 만듭니다.\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out)\n","print([class_names[x] for x in classes])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMfFu9_mfSiP"},"outputs":[],"source":["\n","# 학습 데이터의 배치를 얻습니다.\n","inputs, classes = next(iter(val_dataloader))\n","\n","# 배치로부터 격자 형태의 이미지를 만듭니다.\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out)\n","print([class_names[x] for x in classes])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExxS6jZsfT9n"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def model_evaluation(model, criterion, optimizer, scheduler, num_epochs):\n","    model = model.to(device)\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in tqdm(range(num_epochs)):\n","        \n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","        # print(f\"time per 1 epoch: {time.time() - since:.2f}\")\n","\n","        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n","        for phase in ['train', 'test']:\n","            if phase == 'train':\n","              # pretrained 모델의 학습된 파라미터를 불러옴\n","                # model.load_state_dict(model_state_dict)\n","                model.train()  # 모델을 학습 모드로 설정\n","                running_loss = 0.0\n","                running_corrects = 0\n","\n","                # 데이터를 반복\n","                for inputs, labels in train_dataloader:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    # 매개변수 경사도를 0으로 설정\n","                    optimizer.zero_grad()\n","\n","                    # 순전파\n","                    # 학습 시에만 연산 기록을 추적\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        train_loss = criterion(outputs, labels)\n","\n","                    # 학습 단계인 경우 역전파 + 최적화\n","                    train_loss.backward()\n","                    optimizer.step()\n","\n","                    # 통계\n","                    running_loss += train_loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","\n","                    scheduler.step()\n","\n","                epoch_train_loss = running_loss / train_dataloader\n","                epoch_train_acc = running_corrects.double() / train_dataloader\n","\n","                print(f'train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}')\n","                # wandb.log({'train_acc': epoch_acc, 'train_loss' : epoch_loss})\n","\n","                for inputs, labels in val_dataloader:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    # 매개변수 경사도를 0으로 설정\n","                    optimizer.zero_grad()\n","\n","                    # 순전파\n","                    # 학습 시에만 연산 기록을 추적\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        val_loss = criterion(outputs, labels)\n","\n","                    # 학습 단계인 경우 역전파 + 최적화\n","                    val_loss.backward()\n","                    optimizer.step()\n","\n","                    # 통계\n","                    running_loss += val_loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","\n","                    scheduler.step()\n","\n","                epoch_val_loss = running_loss / val_dataloader\n","                epoch_val_acc = running_corrects.double() / val_dataloader\n","\n","                print(f'val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n","                # wandb.log({'train_acc': epoch_acc, 'train_loss' : epoch_loss})\n","\n","                if epoch_train_acc > best_acc:\n","                    best_acc = epoch_train_acc\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    \n","            \n","            else:\n","                # model.load_state_dict(torch.load(PATH))\n","                model.eval()   # 모델을 평가 모드로 설정\n","                correct = 0\n","                total = 0\n","                with torch.no_grad():\n","                    for image,label in test_dataloader:\n","                        x = image.to(device)\n","                        y= label.to(device)\n","\n","                        output = model.forward(x)\n","                        \n","                        # torch.max함수는 (최댓값,index)를 반환 \n","                        _,output_index = torch.max(output,1)\n","                        \n","                        # 전체 개수 += 라벨의 개수\n","                        total += label.size(0)\n","                        \n","                        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n","                        correct += (output_index == y).sum().float()\n","   \n","        print()\n","        time.sleep(0.1)\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f}')\n","    print(\"Accuracy of Test Data: {}%\".format(100*correct/total))\n","    # wandb.log({'test_acc': best_acc})\n","    \n","\n","    # 가장 나은 모델 가중치를 불러옴\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhWfquN4fWkf"},"outputs":[],"source":["import gc\n","# # from tqdm.notebook import trange, tqdm\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_evaluation(model, criterion, optimizer, exp_lr_scheduler,\n","                       num_epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCkiSjAzfYFl","executionInfo":{"status":"aborted","timestamp":1660464494678,"user_tz":-540,"elapsed":3,"user":{"displayName":"JiHun Bae","userId":"17761386967035840493"}}},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"ViG_test2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNNpd5/rPgUFggGDk8l3Viz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}